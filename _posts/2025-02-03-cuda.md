---
layout: post
author: Mark Hobbs
title: Accelerating peridynamic simulations using Numba CUDA
draft: True
---

This post details the acceleration of the [`pypd`](https://github.com/mark-hobbs/pypd) package using `CUDA`. 

The majority of the simulation time is spent in two functions `particles.compute_forces` and `particles.update_forces`. These have both been optimised using `numba` in a manner similar to that employed when using `OpenMP`... i.e. shared memory type problem...

## `pypd`

Making some simplifications, setting up and running a simulation using `pypd` is broadly as follows:

```python
import pypd

particles = pypd.ParticleSet()
bonds = pypd.BondSet(particles)
model = pypd.Model(particles, bonds)
simulation = pypd.Simulation(n_time_steps=5000)
simulation.run(model)
```

When the simulation is run we need to detect if `CUDA` is available...

```python
class Simulation:

    def __init__(self):
        self.cuda_available = self._is_cuda_available()

    def _is_cuda_available(self):
        """
        Check if CUDA is available
        """
        return cuda.is_available()
```

If `CUDA` is available we need to allocate... to the GPU device...

Device memory allocations and data transfers should typically be done outside the function to:

- Minimise redundant data transfers
- Allow for more efficient memory management
- Enable potential reuse of device-allocated memory across multiple function calls

```python
class Model:
    
    def _allocate_gpu_arrays(self):
        from numba import cuda

        self.particles.x = cuda.to_device(self.particles.x)
        self.particles.x = cuda.to_device(self.particles.u)
```

```python
# Precompute grid and block configurations
self.n_nodes = x.shape[0]
self.n_dimensions = x.shape[1]
self.n_bonds = bondlist.shape[0]

self.threads_per_block = 256
self.blocks_per_grid = (self.n_bonds + self.threads_per_block - 1) // self.threads_per_block
```

### `particles.compute_forces()`

```python
from numba import cuda, float64

@cuda.jit
def compute_bond_forces_kernel(
    x, u, cell_volume, bondlist, c, 
    surface_correction_factors, f_x, f_y, d, 
    material_law_params
):
    """
    CUDA kernel to compute bond forces
    
    Parameters are similar to the original function, with material_law 
    replaced by material_law_params to work with CUDA
    """
    # Thread index
    k_bond = cuda.grid(1)
    
    # Check if thread is within bounds
    if k_bond < bondlist.shape[0]:
        # Get node indices
        node_i = bondlist[k_bond, 0]
        node_j = bondlist[k_bond, 1]

        # Compute reference configuration displacement
        xi_x = x[node_j, 0] - x[node_i, 0]
        xi_y = x[node_j, 1] - x[node_i, 1]

        # Compute current configuration displacement
        xi_eta_x = xi_x + (u[node_j, 0] - u[node_i, 0])
        xi_eta_y = xi_y + (u[node_j, 1] - u[node_i, 1])

        # Compute stretch and length
        xi = numba.float64(np.sqrt(xi_x**2 + xi_y**2))
        y = numba.float64(np.sqrt(xi_eta_x**2 + xi_eta_y**2))
        stretch = (y - xi) / xi

        # Compute damage (simplified material law - may need customization)
        # Assumes material_law_params contains necessary parameters
        damage = material_law_params[0] * stretch + material_law_params[1]
        damage = min(max(damage, 0.0), 1.0)
        d[k_bond] = damage

        # Compute force magnitude
        f = (
            stretch 
            * c[k_bond] 
            * (1 - damage) 
            * cell_volume 
            * surface_correction_factors[k_bond]
        )
        
        # Compute force components
        f_x[k_bond] = f * xi_eta_x / y
        f_y[k_bond] = f * xi_eta_y / y

@cuda.jit
def reduce_forces_kernel(f_x, f_y, bondlist, node_force):
    """
    CUDA kernel to reduce bond forces to node forces
    """
    k_bond = cuda.grid(1)
    
    if k_bond < bondlist.shape[0]:
        node_i = bondlist[k_bond, 0]
        node_j = bondlist[k_bond, 1]

        # Use atomic adds to safely update node forces
        cuda.atomic.add(node_force, (node_i, 0), f_x[k_bond])
        cuda.atomic.add(node_force, (node_j, 0), -f_x[k_bond])
        cuda.atomic.add(node_force, (node_i, 1), f_y[k_bond])
        cuda.atomic.add(node_force, (node_j, 1), -f_y[k_bond])

def compute_nodal_forces_cuda(
    x, u, cell_volume, bondlist, d, c, 
    material_law_params, surface_correction_factors
):
    """
    CUDA-accelerated version of compute_nodal_forces
    
    Parameters:
    -----------
    material_law_params : array-like
        Parameters for the material law (replace the function)
    """
    # Allocate device memory
    x_d = cuda.to_device(x)
    u_d = cuda.to_device(u)
    bondlist_d = cuda.to_device(bondlist)
    c_d = cuda.to_device(c)
    surface_correction_factors_d = cuda.to_device(surface_correction_factors)
    
    # Allocate output arrays on device
    n_nodes = x.shape[0]
    n_dimensions = x.shape[1]
    n_bonds = bondlist.shape[0]
    
    node_force_d = cuda.device_array((n_nodes, n_dimensions), dtype=np.float64)
    f_x_d = cuda.device_array(n_bonds, dtype=np.float64)
    f_y_d = cuda.device_array(n_bonds, dtype=np.float64)
    d_d = cuda.to_device(d)
    
    # Configure grid and block sizes
    threads_per_block = 256
    blocks_per_grid = (n_bonds + threads_per_block - 1) // threads_per_block
    
    # Launch bond forces kernel
    compute_bond_forces_kernel[blocks_per_grid, threads_per_block](
        x_d, u_d, cell_volume, bondlist_d, c_d, 
        surface_correction_factors_d, f_x_d, f_y_d, d_d, 
        material_law_params
    )
    
    # Launch force reduction kernel
    reduce_forces_kernel[blocks_per_grid, threads_per_block](
        f_x_d, f_y_d, bondlist_d, node_force_d
    )
    
    # Copy results back to host
    node_force = node_force_d.copy_to_host()
    d = d_d.copy_to_host()
    
    return node_force, d
```