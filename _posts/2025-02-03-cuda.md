---
layout: post
author: Mark Hobbs
title: Accelerating peridynamic simulations using Numba CUDA
draft: True
---

This post details the acceleration of the [`pypd`](https://github.com/mark-hobbs/pypd) package using `CUDA`. The goal is to ensure that the code requires no changes to the user interface while automatically detecting the presence of a CUDA-enabled device.

The majority of the simulation time is spent in two functions `particles.compute_forces` and `particles.update_positions`. These have both been optimised using `numba` in a manner analagous to shared-memory parallelism with `OpenMP`. The existing implementation does not support distributed-memory architectures (e.g., `MPI`), and as such, the maximum problem size is limited by the memory capacity of a single CPU - typically allowing for simulations of 1 to 10 million particles.

We are going to employ [`numba-cuda`](https://github.com/NVIDIA/numba-cuda) to make the CUDA implementation as easy and seamless as possible.

## The CUDA programming model

Before writing the CUDA kernel, we briefly review the CUDA programming model. The CUDA programming model provides an abstraction of the GPU architecture that acts as a bridge between an application and its possible implementation on GPU hardware. See this [post](https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/) for further details.

```bash
CUDA Device Information:
----------------------------------------
Device Name:              b'Tesla T4'
Compute Capability:       (7, 5)

Memory:
Total Memory:             15.83 GB
Free Memory:              15.72 GB

Compute Resources:
Multiprocessors:          40
Max Threads per Block:    1024

Grid Limitations:
Max Grid Dimensions X:    2147483647
Max Grid Dimensions Y:    65535
Max Grid Dimensions Z:    65535

Additional Characteristics:
Warp Size:                32
Clock Rate:               1.59 GHz
Memory Clock Rate:        5.00 GHz
```

#### 1. Device (GPU)

- Physical hardware accelerator
- Contains multiple Streaming Multiprocessors (SMs)
- Manages global memory and computation resources

#### 2. Streaming Multiprocessors (SMs)

- Core computational units of the GPU
- Contains:
  - CUDA Cores
  - Shared Memory
  - Register File
  - Special Function Units
  - Warp Schedulers

#### 3. Threads

- Smallest unit of execution
- Analogous to a single computational task
- Organised into blocks and grids

#### 4. Thread Blocks

- Collection of threads that can:
  - Share shared memory
  - Synchronise with each other
  - Execute on a single Streaming Multiprocessor (SM)

#### 5. Grid

- Highest-level organisational unit
- Collection of thread blocks
- All blocks in a grid execute the same kernel

### Memory Hierarchy

#### Global Memory

- Largest, slowest memory
- Accessible by all threads
- Resides on device DRAM
- High latency, low bandwidth

#### Shared Memory

- On-chip memory within an SM
- Explicitly managed by programmer
- Much faster than global memory
- Shared by all threads in a block

#### Register Memory

- Fastest memory
- Private to each thread
- Limited in size
- Located directly on the SM

#### Constant Memory

- Read-only cache
- Optimised for broadcast scenarios
- Good for data accessed by multiple threads

#### Texture Memory

- Read-only cache
- Optimised for 2D spatial locality
- Hardware interpolation support

### Execution Model

#### Warp

- Basic unit of thread execution
- Typically 32 threads
- Executed in SIMT (Single Instruction, Multiple Thread) mode
- All threads in a warp execute the same instruction

#### Occupancy

- Measure of active warps per SM
- Determines computational efficiency
- Influenced by:
  - Kernel resource usage
  - SM capabilities
  - Available registers
  - Shared memory consumption

### Kernel Launch Configuration

#### Threads per Block

- Typically multiples of 32 (warp size)
- Maximum usually 1024 threads
- Constrained by:
  - Available registers
  - Shared memory
  - Compute capability

#### Blocks per Grid

- Determined by total work items
- Limited by device capabilities
- Typically calculated as:
  ```python
  blocks_per_grid = (total_work_items + threads_per_block - 1) // threads_per_block
  ```

## `pypd`

Making some simplifications, setting up and running a simulation using `pypd` is broadly as follows:

```python
import pypd

particles = pypd.ParticleSet()
bonds = pypd.BondSet(particles)
model = pypd.Model(particles, bonds)
simulation = pypd.Simulation(n_time_steps=5000)
simulation.run(model)
```

When the simulation is run we need to detect if `CUDA` is available and then allocate memory to the device.

```python
from numba import cuda


class Simulation:

    def __init__(self):
        self.cuda_available = self._is_cuda_available()
        print(f"Is CUDA available: {self.cuda_available}")
        if self.cuda_available:
            get_cuda_device_info()

    def _is_cuda_available(self):
        """
        Check if CUDA is available
        """
        return cuda.is_available()

    def run(self, model):
        """
        Run the simulation
        """
        if self.cuda_available:
            model._allocate_gpu_arrays()
```

Device memory allocations and data transfers should typically be done outside the CUDA kernel to:

- Minimise redundant data transfers
- Allow for more efficient memory management
- Enable potential reuse of device-allocated memory across multiple function calls

```python
class Model:
    
    def _allocate_gpu_arrays(self):
        from numba import cuda
        cuda.to_device(self.particles.x)
        cuda.to_device(self.particles.u)
        cuda.to_device(self.particles.v)
        cuda.to_device(self.particles.a)
        cuda.to_device(self.particles.f)
        cuda.to_device(self.particles.bc.flag)
        cuda.to_device(self.particles.bc.unit_vector)
        cuda.to_device(self.bonds.c)
        cuda.to_device(self.bonds.d)
        cuda.to_device(self.bonds.f_x)
        cuda.to_device(self.bonds.f_y)
```

```python
class ParticleSet:

     def compute_forces(self, bonds, cuda_available):
        """
        Compute particle forces

        Parameters
        ----------
        bonds : BondSet
            TODO: write a description

        Returns
        -------
        particles.f: ndarray (float)
            Particle forces
        
        Notes
        -----
        """
        if cuda_available:
            compute_nodal_forces_cuda()
        else:
            self.f, _ = compute_nodal_forces(
                self.x,
                self.u,
                self.cell_volume,
                bonds.bondlist,
                bonds.d,
                bonds.c,
                bonds.f_x,
                bonds.f_y,
                bonds.constitutive_law.calculate_bond_damage,
                bonds.surface_correction_factors,
            )

```

Modify the arrays in place...

```python
class EulerCromer(Integrator):

    def one_timestep(self, particles, simulation):
        """
        Update particle positions using an Euler-Cromer time integration scheme

        Parameters
        ----------

        Returns
        -------

        Notes
        -----
        * self.dt or simulation.dt?

        """
        if simulation.cuda_available:
            return euler_cromer_cuda()
        else:
            return euler_cromer(
                particles.f,
                particles.u,
                particles.v,
                particles.a,
                particles.node_density,
                particles.bc.flag,
                particles.bc.i_magnitude,
                particles.bc.unit_vector,
                simulation.damping,
                simulation.dt
            )
```

```python
class Simulation:

    def _single_time_step(self, model):
        """
        Single time step
        """
        model.particles.compute_forces(model.bonds, self.cuda_available)
        model.particles.update_positions(self)

        if model.penetrators:
            for penetrator in model.penetrators:
                penetrator.calculate_penetrator_force(model.particles, self)

        if self.animation and self.i_time_step % self.animation.frequency == 0:
            self.animation.save_frame(model.particles, model.bonds)
```

### CUDA Kernel

```python
from numba import cuda, float64


@cuda.jit
def compute_bond_forces_kernel(
    x_d, u_d, cell_volume, bondlist_d, c_d, 
    surface_correction_factors_d, f_x_d, f_y_d, d_d, 
    cuda_material_law
):
    """
    CUDA kernel to compute bond forces with flexible material law
    """
    k_bond = cuda.grid(1)
    
    if k_bond < bondlist_d.shape[0]:
        node_i = bondlist_d[k_bond, 0]
        node_j = bondlist_d[k_bond, 1]

        xi_x = x_d[node_j, 0] - x_d[node_i, 0]
        xi_y = x_d[node_j, 1] - x_d[node_i, 1]

        xi_eta_x = xi_x + (u_d[node_j, 0] - u_d[node_i, 0])
        xi_eta_y = xi_y + (u_d[node_j, 1] - u_d[node_i, 1])

        xi = np.sqrt(xi_x**2 + xi_y**2)
        y = np.sqrt(xi_eta_x**2 + xi_eta_y**2)
        stretch = (y - xi) / xi

        # Use the flexible material law
        damage = material_law(k_bond, stretch, d_d[k_bond])
        
        # Ensure damage is between 0 and 1
        damage = max(0.0, min(damage, 1.0))
        d_d[k_bond] = damage

        f = (
            stretch 
            * c_d[k_bond] 
            * (1 - damage) 
            * cell_volume 
            * surface_correction_factors_d[k_bond]
        )
        
        f_x_d[k_bond] = f * xi_eta_x / y
        f_y_d[k_bond] = f * xi_eta_y / y
```

Efficiently reduce bond forces to node forces using parallel binary reduction.

```python
@cuda.jit
def reduce_forces_kernel(f_x_d, f_y_d, bondlist_d, node_force_d):
    """
    CUDA kernel to reduce bond forces to node forces
    """
    k_bond = cuda.grid(1)
    
    if k_bond < bondlist_d.shape[0]:
        node_i = bondlist_d[k_bond, 0]
        node_j = bondlist_d[k_bond, 1]

        cuda.atomic.add(node_force_d, (node_i, 0), f_x_d[k_bond])
        cuda.atomic.add(node_force_d, (node_j, 0), -f_x_d[k_bond])
        cuda.atomic.add(node_force_d, (node_i, 1), f_y_d[k_bond])
        cuda.atomic.add(node_force_d, (node_j, 1), -f_y_d[k_bond])
```

### `ParticleSet`

```python
class ParticleSet:

    def compute_nodal_forces(self, cell_volume, d, material_law):
        """
        Compute nodal forces using pre-allocated device memory
        
        Parameters:
        -----------
        cell_volume : float
            Volume of computational cell
        d : ndarray
            Current bond damage state
        material_law : callable
            Function to compute bond damage
        
        Returns:
        --------
        node_force : ndarray
            Computed nodal forces
        updated_d : ndarray
            Updated damage state
        """    
        # Allocate or reuse device arrays for this computation
        node_force_d = cuda.device_array((self.n_nodes, self.n_dimensions), dtype=np.float64)
        f_x_d = cuda.device_array(self.n_bonds, dtype=np.float64)
        f_y_d = cuda.device_array(self.n_bonds, dtype=np.float64)
        d_d = cuda.to_device(d)
        
        # Launch bond forces kernel
        compute_bond_forces_kernel[self.blocks_per_grid, self.threads_per_block](
            self.x_d, self.u_d, cell_volume, 
            self.bondlist_d, self.c_d, 
            self.surface_correction_factors_d, 
            f_x_d, f_y_d, d_d, 
            cuda_material_law
        )
        
        # Launch force reduction kernel
        reduce_forces_kernel[self.blocks_per_grid, self.threads_per_block](
            f_x_d, f_y_d, self.bondlist_d, node_force_d
        )
        
        # Copy results back to host
        node_force = node_force_d.copy_to_host()
        updated_d = d_d.copy_to_host()
        
        return node_force, updated_d
```

### `ConstitutiveLaw`

We need to write a utility function (wrapper function) to create a CUDA-compatible material law. The material law is called with the signature `material_law(k_bond, s, d)`...

```python
class ConstitutiveLaw:

    def create_cuda_material_law(material_law):
        """
        Convert a Python material law function to a CUDA-compatible form
        
        Parameters:
        -----------
        material_law : callable
            A function that takes (k_bond, stretch, current_damage) 
            and returns updated damage
        
        Returns:
        --------
        cuda_material_law : ndarray
            A pre-compiled CUDA-compatible material law
        """
        # Create a wrapper that can be used in CUDA kernel
        @cuda.jit(device=True)
        def cuda_material_law_wrapper(k_bond, stretch, current_damage):
            # We'll use a global array to pass the function
            return material_law_global[0](k_bond, stretch, current_damage)
        
        # Create a global reference to the original material law
        global material_law_global
        material_law_global = [material_law]
        
        return cuda_material_law_wrapper
```

## Useful links

- [Numba for CUDA programmers](https://github.com/numba/nvidia-cuda-tutorial)
- [An even easier introduction to CUDA](https://developer.nvidia.com/blog/even-easier-introduction-cuda/)
- [CUDA programming guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)
- [The CUDA programming model](https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/)
- [Optimising parallel reduction in CUDA](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf)
- [numba.readthedocs](https://numba.readthedocs.io/en/0.60.0/)
- [https://numba.readthedocs.io/en/stable/cuda/index.html](https://numba.readthedocs.io/en/stable/cuda/index.html)
- [https://nvidia.github.io/numba-cuda/](https://nvidia.github.io/numba-cuda/)
- [GPU Programming in Pure Python - Bryce Adelstein Lelbach](https://www.youtube.com/watch?v=8utSRblGEB0&ab_channel=PyConUS)