---
layout: post
author: Mark Hobbs
title: Accelerating peridynamic simulations using CUDA and Numba
draft: True
---

This post details the acceleration of the [`pypd`](https://github.com/mark-hobbs/pypd) package using `CUDA`. 

The majority of the simulation time is spent in two functions `particles.compute_forces` and `particles.update_forces`. These have both been optimised using `numba` in a manner similar to that employed when using `OpenMP`... i.e. shared memory type problem...

## `pypd`

Making some simplifications, setting up and running a simulation using `pypd` is broadly as follows:

```python
import pypd

particles = pypd.ParticleSet()
bonds = pypd.BondSet(particles)
model = pypd.Model(particles, bonds)
simulation = pypd.Simulation(n_time_steps=5000)
simulation.run(model)
```

When the simulation is run we need to detect if `CUDA` is available...

```python
class Simulation:

    def __init__(self):
        self.cuda_available = self._is_cuda_available()

    def _is_cuda_available(self):
        """
        Check if CUDA is available
        """
        return cuda.is_available()
```

If `CUDA` is available we need to allocate... to the GPU device...

```python
class Model:
    
    def _allocate_gpu_arrays(self):
        from numba import cuda

        self.particles.x = cuda.to_device(self.particles.x)
        self.particles.x = cuda.to_device(self.particles.u)
```